{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "from scipy import stats\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "\n",
    "from ete3 import NCBITaxa\n",
    "ncbi = NCBITaxa()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commands\n",
    "### CDS\n",
    "cat blastp_nr_karect26_300_CDS.txt | grep \"Query= \\|^gi|\" > blastp_nr_CDS\n",
    "\n",
    "cat blastp_nr_CDS | sed -e 's/|  /,,,/g'| sed -e 's/         /,,,/g'|sed -e 's/        /,,,/g' |sed -e 's/       /,,,/g' | sed -e 's/      /,,,/g' |sed -e 's/     /,,,/g' | sed -e 's/    /,,,/g' | sed -e 's/   /,,,/g'| sed -e 's/  /,,,/g'| sed -e 's/|,/,,,/g'| sed -e 's/gi|//g'| sed -e 's/|gb|/,,,gb,,,/g'| sed -e 's/|ref|/,,,ref,,,/g'| sed -e 's/|emb|/,,,emb,,,/g'| sed -e 's/|pdb|/,,,pdb,,,/g' | sed -e 's/|dbj|/,,,dbj,,,/g' | sed -e 's/|tpg|/,,,tpg,,,/g'| sed -e 's/|sp|/,,,sp,,,/g'| sed -e 's/|prf|/,,,prf,,,/g'| sed -e 's/|pir|/,,,pir,,,/g'| sed -e 's/|tpe|/,,,tpe,,,/g' > temp_CDS\n",
    "\n",
    "### contigs\n",
    "cat blastp_nr_karect26_300_contigs.txt | grep \"Query= \\|^gi|\" > blastp_nr_contigs\n",
    "\n",
    "cat blastp_nr_contigs | sed -e 's/|  /,,,/g'| sed -e 's/         /,,,/g'|sed -e 's/        /,,,/g' |sed -e 's/       /,,,/g' | sed -e 's/      /,,,/g' |sed -e 's/     /,,,/g' | sed -e 's/    /,,,/g' | sed -e 's/   /,,,/g'| sed -e 's/  /,,,/g'| sed -e 's/|,/,,,/g'| sed -e 's/gi|//g'| sed -e 's/|gb|/,,,gb,,,/g'| sed -e 's/|ref|/,,,ref,,,/g'| sed -e 's/|emb|/,,,emb,,,/g'| sed -e 's/|pdb|/,,,pdb,,,/g' | sed -e 's/|dbj|/,,,dbj,,,/g' | sed -e 's/|tpg|/,,,tpg,,,/g'| sed -e 's/|sp|/,,,sp,,,/g'| sed -e 's/|prf|/,,,prf,,,/g'| sed -e 's/|pir|/,,,pir,,,/g'| sed -e 's/|tpe|/,,,tpe,,,/g' > temp_contigs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input BLAST results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "tmp_CDS = pd.read_csv('Data/temp_CDS', header=None, names=col, sep=',,,', engine='python')\n",
    "tmp_contigs = pd.read_csv('Data/temp_contigs', header=None, names=col, sep=',,,', engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rearrangement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Del_NA(df, startcol, endcol):\n",
    "    \n",
    "    for c in range(startcol, endcol):\n",
    "        \n",
    "        index_list = list(df.dropna(subset=[c])[df.dropna(subset=[c])[c+1].isna()].index)\n",
    "        \n",
    "        for i in range(len(index_list)):\n",
    "            df.iat[index_list[i], 4] = df.iat[index_list[i], c-1]\n",
    "            df.iat[index_list[i], 5] = df.iat[index_list[i], c]\n",
    "    \n",
    "    dfout =df[[0,2,4,5]]\n",
    "    dfout.columns = ['gi','accession','score','e-value']\n",
    "\n",
    "    return dfout\n",
    "\n",
    "def Rearrangement_BLASTresult(df):\n",
    "    dfdelna = Del_NA(df, 6, 10)\n",
    "    \n",
    "    # query identifier list \n",
    "    seqlist = dfdelna[dfdelna['gi'].str.contains('Query=')]['gi'].str.replace('Query= ', '').str.split(' ', expand=True).loc[:,[0]]\n",
    "    dfout = pd.concat([dfdelna, seqlist[0]], axis=1, join_axes=[dfdelna.index])\n",
    "\n",
    "    # fill query identifier\n",
    "    dfout[0] = dfout[0].fillna(method=\"ffill\")\n",
    "    dfout = dfout.rename(columns={0:'SeqIden'})\n",
    "    dfout['TrinityIden'] = dfout['SeqIden'].str.replace('|','\\t').str.split('\\t', expand=True)[0]\n",
    "\n",
    "    # delete col (Query=)\n",
    "    dfout = dfout.drop(seqlist.index)\n",
    "    dfout['rank'] = range(len(dfout))\n",
    "    \n",
    "    # all sequence list\n",
    "    seqlist[1] = seqlist[0].str.replace('|','\\t').str.split('\\t', expand=True)[0]\n",
    "    seqlist.columns=['SeqIden','TrinityIden']\n",
    "\n",
    "    return seqlist, dfout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gi</th>\n",
       "      <th>accession</th>\n",
       "      <th>score</th>\n",
       "      <th>e-value</th>\n",
       "      <th>SeqIden</th>\n",
       "      <th>TrinityIden</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1088597648</td>\n",
       "      <td>OHE15404.1</td>\n",
       "      <td>205</td>\n",
       "      <td>2.000000e-61</td>\n",
       "      <td>TRINITY_DN10013_c0_g1_i1</td>\n",
       "      <td>TRINITY_DN10013_c0_g1_i1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1088600340</td>\n",
       "      <td>OHE17577.1</td>\n",
       "      <td>204</td>\n",
       "      <td>6.000000e-61</td>\n",
       "      <td>TRINITY_DN10013_c0_g1_i1</td>\n",
       "      <td>TRINITY_DN10013_c0_g1_i1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1334725090</td>\n",
       "      <td>PNV84571.1</td>\n",
       "      <td>208</td>\n",
       "      <td>8.000000e-61</td>\n",
       "      <td>TRINITY_DN10013_c0_g1_i1</td>\n",
       "      <td>TRINITY_DN10013_c0_g1_i1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1088600246</td>\n",
       "      <td>OHE17493.1</td>\n",
       "      <td>204</td>\n",
       "      <td>1.000000e-60</td>\n",
       "      <td>TRINITY_DN10013_c0_g1_i1</td>\n",
       "      <td>TRINITY_DN10013_c0_g1_i1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1243954385</td>\n",
       "      <td>WP_096047732.1</td>\n",
       "      <td>207</td>\n",
       "      <td>2.000000e-60</td>\n",
       "      <td>TRINITY_DN10013_c0_g1_i1</td>\n",
       "      <td>TRINITY_DN10013_c0_g1_i1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           gi       accession score       e-value                   SeqIden  \\\n",
       "1  1088597648      OHE15404.1   205  2.000000e-61  TRINITY_DN10013_c0_g1_i1   \n",
       "2  1088600340      OHE17577.1   204  6.000000e-61  TRINITY_DN10013_c0_g1_i1   \n",
       "3  1334725090      PNV84571.1   208  8.000000e-61  TRINITY_DN10013_c0_g1_i1   \n",
       "4  1088600246      OHE17493.1   204  1.000000e-60  TRINITY_DN10013_c0_g1_i1   \n",
       "5  1243954385  WP_096047732.1   207  2.000000e-60  TRINITY_DN10013_c0_g1_i1   \n",
       "\n",
       "                TrinityIden  rank  \n",
       "1  TRINITY_DN10013_c0_g1_i1     0  \n",
       "2  TRINITY_DN10013_c0_g1_i1     1  \n",
       "3  TRINITY_DN10013_c0_g1_i1     2  \n",
       "4  TRINITY_DN10013_c0_g1_i1     3  \n",
       "5  TRINITY_DN10013_c0_g1_i1     4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CDSSeqlist, CDSNR= Rearrangement_BLASTresult(tmp_CDS)\n",
    "CDSNR.head()\n",
    "\n",
    "ContigSeqlist, ContigNR= Rearrangement_BLASTresult(tmp_contigs)\n",
    "ContigNR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#All Contigs: 146985\n",
      "#All CDSs: 109253\n",
      "#Anotated CDSs: 97944\n",
      "#Anotated CDS (Contig): 87029\n",
      "#Anotated Contigs: 126896\n",
      "#Anotated Contigs: 126896\n"
     ]
    }
   ],
   "source": [
    "print(\"#All Contigs:\", len(set(ContigSeqlist['SeqIden'])))\n",
    "print(\"#All CDSs:\", len(set(CDSSeqlist['SeqIden'])))\n",
    "print(\"#Anotated CDSs:\", len(set(CDSNR['SeqIden'])))\n",
    "print(\"#Anotated CDS (Contig):\", len(set(CDSNR['TrinityIden'])))\n",
    "print(\"#Anotated Contigs:\", len(set(ContigNR['SeqIden']))) #*\n",
    "print(\"#Anotated Contigs:\", len(set(ContigNR['TrinityIden'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11309\n",
      "49637\n",
      "10634\n",
      "39003\n"
     ]
    }
   ],
   "source": [
    "# CDS without annotation\n",
    "CDSNoNR=CDSSeqlist[~CDSSeqlist['SeqIden'].isin(set(CDSNR['SeqIden']))]\n",
    "print(len(set(CDSNoNR['SeqIden'])))\n",
    "\n",
    "# contigs without CDS\n",
    "NoCDSContig=ContigSeqlist[~ContigSeqlist['TrinityIden'].isin(set(CDSSeqlist['TrinityIden']))]\n",
    "print(len(set(NoCDSContig['TrinityIden'])))\n",
    "\n",
    "# NoCDSContig without annotation\n",
    "NoCDSContigNoNR=NoCDSContig[~NoCDSContig['TrinityIden'].isin(set(ContigNR['TrinityIden']))]\n",
    "print(len(set(NoCDSContigNoNR['TrinityIden'])))\n",
    "\n",
    "# NoCDSContig with annotation\n",
    "tmp=NoCDSContig[~NoCDSContig['TrinityIden'].isin(set(NoCDSContigNoNR['TrinityIden']))]\n",
    "\n",
    "NoCDSContigNR=ContigNR[ContigNR['TrinityIden'].isin(set(tmp['TrinityIden']))]\n",
    "print(len(set(NoCDSContigNR['TrinityIden'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136947\n",
      "126032\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([CDSNR, NoCDSContigNR])\n",
    "print(len(set(df['SeqIden'])))\n",
    "print(len(set(df['TrinityIden'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve top hits assigned to major taxa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_list1 = pd.read_table('/nfs_share/motoki/metatra/201809_metatra/data/ftp.ncbi.nlm.nih.gov/pub/taxonomy/accession2taxid/prot.accession2taxid', usecols=[1,2], header=0, names=('accession','taxid'))\n",
    "pro_list2 = pd.read_table('/nfs_share/motoki/metatra/201809_metatra/data/ftp.ncbi.nlm.nih.gov/pub/taxonomy/accession2taxid/pdb.accession2taxid', usecols=[1,2], header=0, names=('accession','taxid'))\n",
    "acc2taxid = pd.concat([pro_list1, pro_list2], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dominant_blast_results():\n",
    "    \n",
    "    # 1 major taxa's taxid\n",
    "    MajorTaxid = []\n",
    "    \n",
    "    for i in range(len(taxalist)):\n",
    "        MajorTaxid.extend(ncbi.get_descendant_taxa(taxalist[i]))\n",
    "        \n",
    "    MajorTaxid = set(MajorTaxid)\n",
    "\n",
    "    # 2 major taxa's accession\n",
    "    MajorAcc = set(acc2taxid[acc2taxid['taxid'].isin(MajorTaxid)]['accession'])\n",
    "    print('MajorAccession: ', len(MajorAcc)) \n",
    "\n",
    "    # 3 extaract data from blast result\n",
    "    dfmajor = df[df['accession'].isin(MajorAcc)]\n",
    "    dfnotmajor = df[~df['SeqIden'].isin(set(dfmajor['SeqIden']))]\n",
    "    \n",
    "    return dfmajor, dfnotmajor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MajorAccession:  834903\n",
      "91926\n",
      "100579\n",
      "35313\n",
      "36368\n"
     ]
    }
   ],
   "source": [
    "taxalist = ['Sulfurovum', 'Methylococcales', 'Thiotrichales']\n",
    "dfmajor, dfnotmajor = dominant_blast_results()\n",
    "\n",
    "print(len(set(dfmajor['TrinityIden'])))\n",
    "print(len(set(dfmajor['SeqIden'])))\n",
    "\n",
    "print(len(set(dfnotmajor['TrinityIden'])))\n",
    "print(len(set(dfnotmajor['SeqIden'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Retrieve_tophits(dfdat):\n",
    "    \n",
    "    SeqIden = list(set(dfdat[\"SeqIden\"]))\n",
    "    dfoutput = pd.DataFrame(columns=dfdat.columns)\n",
    "\n",
    "    for i in range(len(SeqIden)):\n",
    "        \n",
    "        # largest bitscore\n",
    "        tmp = dfdat[(dfdat[\"SeqIden\"] == SeqIden[i])]\n",
    "        bitMAX = tmp[(tmp.score.astype(float) == tmp.score.astype(float).max())]\n",
    "                \n",
    "        if len(bitMAX) == 1:\n",
    "            dfoutput.loc[i]=bitMAX.iloc[0,]\n",
    "            \n",
    "        # bitscore in a tie: minimum evalue\n",
    "        elif len(bitMAX) != 1:\n",
    "            EvalueMIN = bitMAX[(bitMAX['e-value'].astype(float) == bitMAX['e-value'].astype(float).min())]\n",
    "            \n",
    "            if len(EvalueMIN) == 1:\n",
    "                dfoutput.loc[i]=EvalueMIN.iloc[0,]\n",
    "                \n",
    "            # both of bitscore and evalue in a tie: first row\n",
    "            else:\n",
    "                dfoutput.loc[i]=EvalueMIN.iloc[0,]\n",
    "            \n",
    "    return dfoutput\n",
    "\n",
    "\n",
    "def Divid_Seq(dfdat):\n",
    "    \n",
    "    dfoutput = pd.DataFrame(columns=list(dfdat.columns))\n",
    "    \n",
    "    SeqIden = list(set(dfdat[\"SeqIden\"]))\n",
    "\n",
    "    sep = 5000\n",
    "    sepfiles = round(len(SeqIden)/sep) + 1\n",
    "    \n",
    "    for i in range(sepfiles):\n",
    "        \n",
    "        # extract 'sep' of each sequence\n",
    "        Sequences = set(SeqIden[sep*i:sep*(i+1)])\n",
    "        tmp = dfdat[dfdat[\"SeqIden\"].isin(Sequences)]\n",
    "        \n",
    "        output = Retrieve_tophits(tmp)\n",
    "        \n",
    "        # confirm < 5000 ('sep')\n",
    "        if i == sepfiles -1:\n",
    "            print('sequences:', len(list(set(tmp[\"SeqIden\"]))))\n",
    "            print(sepfiles)\n",
    "    \n",
    "        dfoutput = pd.concat([dfoutput, output])\n",
    "        \n",
    "    return dfoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences: 579\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "dfmajor_tophit = Divid_Seq(dfmajor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences: 1368\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "dfnotmajor_tophit = Divid_Seq(dfnotmajor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136947\n"
     ]
    }
   ],
   "source": [
    "dftophit = pd.concat([dfmajor_tophit, dfnotmajor_tophit])\n",
    "print(len(dftophit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get taxonomic information for accession number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "AssignedAcc = acc2taxid[acc2taxid['accession'].isin(set(dftophit['accession']))]\n",
    "taxid_list = list(set(AssignedAcc['taxid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_swap_dict(d):\n",
    "    return {v: k for k, v in d.items()}\n",
    "\n",
    "\n",
    "def get_all_taxid(taxid_list):\n",
    "    \n",
    "    df = pd.DataFrame(columns=['superkingdom','phylum','class','subphylum','family','genus','order','species'])\n",
    "\n",
    "    for i in range(len(taxid_list)):\n",
    "        lineage = ncbi.get_lineage(taxid_list[i])\n",
    "        data = ncbi.get_rank(lineage)\n",
    "\n",
    "        d_swap = get_swap_dict(data)\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame(d_swap, index=[taxid_list[i],])], sort=False)\n",
    "\n",
    "    df = df.fillna(0)  # No taxid 0 in NCBItaxa\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_all_taxid_info(taxid_list):\n",
    "\n",
    "    dfoutput = get_all_taxid(taxid_list)\n",
    "    \n",
    "    for j in range(len(taxid_list)):\n",
    "        the_list = list(dfoutput.loc[taxid_list[j],])\n",
    "\n",
    "        for i in range(len(the_list)):\n",
    "            if the_list[i] == 0:\n",
    "                continue\n",
    "\n",
    "            info = ncbi.get_taxid_translator([the_list[i]])\n",
    "\n",
    "            dfoutput.iloc[j:j+1,i] = info[the_list[i]]\n",
    "            \n",
    "    dfoutput = dfoutput.reset_index()\n",
    "    dfoutput = dfoutput.rename(columns={'index':'taxid'})\n",
    "            \n",
    "    return dfoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TaxidInfo = get_all_taxid_info(taxid_list)\n",
    "\n",
    "dfinfo = pd.merge(AssignedAcc, TaxidInfo.loc[:,'taxid':'species'], on='taxid', how='left')\n",
    "dftophit_taxa = pd.merge(dftophit, dfinfo, on='accession', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNR = pd.concat([dftophit_taxa, CDSNoNR, NoCDSContigNoNR], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all data 158890\n",
      "all data (CDSs) 158890\n",
      "all data (contigs) 146985\n"
     ]
    }
   ],
   "source": [
    "print(\"all data\", len(dfNR))  # 156430\n",
    "print(\"all data (CDSs)\", len(set(dfNR[\"SeqIden\"])))  # 146985\n",
    "print(\"all data (contigs)\", len(set(dfNR[\"TrinityIden\"])))  # 146985"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input KEGG annotation and TPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146985\n"
     ]
    }
   ],
   "source": [
    "# KEGG annotation\n",
    "KOCDS = pd.read_csv('Data/out_out_out_blastp_tophit_nr_S', skiprows=[0], header=None, sep='\\t',\n",
    "                   usecols=[0,1,4,23], names=['SeqIden','Qlen','Slen','KO'])\n",
    "\n",
    "KOContigs = pd.read_csv('Data/out_out_out_blastx_tophit_nr_S', skiprows=[0], header=None, sep='\\t',\n",
    "                   usecols=[0,1,4,23], names=['SeqIden','Qlen','Slen','KO'])\n",
    "\n",
    "KOs = pd.concat([KOCDS, KOContigs])\n",
    "\n",
    "\n",
    "# TPM\n",
    "insitu1 = pd.read_csv(\n",
    "    'Data/insitu_4_1_2.isoforms.results', \n",
    "    header=None, skiprows=[0], sep='\\t', usecols=[0,2,3,4,5], \n",
    "    names=['TrinityIden','gene_id_len','expected_len','insitu1_count','insitu1']\n",
    ")\n",
    "\n",
    "insitu2 = pd.read_csv(\n",
    "    'Data/insitu_8_3.isoforms.results', \n",
    "    header=None, skiprows=[0], sep='\\t', usecols=[0,4,5], names=['TrinityIden','insitu2_count','insitu2']\n",
    ")\n",
    "\n",
    "onboard1 = pd.read_csv(\n",
    "    'Data/onboard_2_1_2.isoforms.results', \n",
    "    header=None, skiprows=[0], sep='\\t', usecols=[0,4,5], names=['TrinityIden','onboard1_count','onboard1']\n",
    ")\n",
    "\n",
    "onboard2 = pd.read_csv(\n",
    "    'Data/onboard_10_1_2.isoforms.results', \n",
    "    header=None, skiprows=[0], sep='\\t', usecols=[0,4,5], names=['TrinityIden','onboard2_count','onboard2']\n",
    ")\n",
    "\n",
    "dfTPM = pd.merge(insitu1, insitu2, on='TrinityIden')\n",
    "dfTPM = pd.merge(dfTPM, onboard1, on='TrinityIden')\n",
    "dfTPM = pd.merge(dfTPM, onboard2, on='TrinityIden')\n",
    "\n",
    "print(len(dfTPM))   # 146985\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158890\n",
      "146985\n"
     ]
    }
   ],
   "source": [
    "dfNRKG = pd.merge(dfNR, KOs, on='SeqIden', how='left')\n",
    "dfNRKG_tpm = pd.merge(dfNRKG, dfTPM, on='TrinityIden', how='left')\n",
    "\n",
    "print(len(dfNRKG_tpm))  # 158890\n",
    "print(len(set(dfNRKG_tpm['TrinityIden'])))   # 146985"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNRKG_tpm.to_csv(\"Data/NRKG_tpm\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
